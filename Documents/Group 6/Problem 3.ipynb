{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26d5df7",
   "metadata": {},
   "source": [
    "### Task 3. In Feature Engineering part, given a sentence s, we build two features: the positive frequency of s and the negative frequency of s. Given a sentence s, normalize these two features with respect to N = train_set_length * the length of s. Compare your result with the original one in the course. Is that normalization a good thing to do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cef32ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_set_length = \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_x\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_features_with_normalization\u001b[39m(tweet, freqs, process_tweet=process_tweet):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# process_tweet tokenizes, stems, and removes stopwords\u001b[39;00m\n\u001b[32m      4\u001b[39m     word_l = process_tweet(tweet)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "train_set_length = len(train_x)\n",
    "def extract_features_with_normalization(tweet, freqs, process_tweet=process_tweet):\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    length_word = len(word_l)\n",
    "    N = train_set_length*length_word\n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        if (word, 1) in freqs.keys():\n",
    "            x[0,1] += freqs[(word, 1)]\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        if (word, 0) in freqs.keys():\n",
    "            x[0,2] += freqs[(word, 0)]\n",
    "    x[0,1] = x[0,1] / N\n",
    "    x[0,2] = x[0,2] / N\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet_with_normalization(tweet, freqs, theta):\n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features_with_normalization(tweet, freqs)\n",
    "    # make the prediction using x and theta\n",
    "    y_pred = sigmoid(np.dot(x, theta))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7412a6",
   "metadata": {},
   "source": [
    "Some practice to compare the normalized features with the original ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6110b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"original:\")\n",
    "for i in range(1, 5):\n",
    "    sent = \" \".join([\"great\"] * i)\n",
    "    print(f\"{sent} -> {predict_tweet(sent,freqs,w).item():.6f}\")\n",
    "\n",
    "print(\"\\nafter normalization:\")\n",
    "for i in range(1, 5):\n",
    "    sent = \" \".join([\"great\"] * i)\n",
    "    print(f\"{sent} -> {predict_tweet_with_normalization(sent,freqs,w).item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfae7ca4",
   "metadata": {},
   "source": [
    " - EXPLAIN\n",
    "    * Normalization removes the impact of word repetition in a tweet on the predicted probability.\n",
    "        - ![image.png](attachment:image-3.png)\n",
    "    * Suppose the entry (\"great\", 1) in the freqs dictionary equals i, indicating that the word \"great\" occurs i times across all positive tweets.\n",
    "        -  for \"great\":\n",
    "\n",
    "            x_pos = i/(train_set_length * 1)\n",
    "\n",
    "        - for \"great great great great\": \n",
    "\n",
    "            x_neg = 4i/(train_set_length * 4)\n",
    "        - Therefore, x_pos has the same value in both cases. Likewise, x_neg is identical in the two cases because it corresponds to the negative frequency.\n",
    "\n",
    "        ![image-2.png](attachment:image-2.png)\n",
    "        \n",
    "        * Thus, normalization may not be appropriate for sentiment analysis, as the repetition of positive or negative words within a tweet carries meaningful information.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
