{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a73bb3",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "#### **Sentiment Analysis**. The idea is that we will equip our students with nothing beforehand and we will build a Sentiment Analysis \"solution\" from scratch quickly. \n",
    "In first two sessions, we will cover the following:  \n",
    "* Some basic text processing (to handle comments, feedbacks, reviews, complaints).\n",
    "* A bit of feature engineering to extract relevant information for Sentiment Analysis task.\n",
    "* How to build and run a basic ML model on those features for Sentiment Analysis task. In this part, we will have a deep review on Logistic Regression and Na√Øve Bayes models in NLP context.\n",
    "\n",
    "Note: For the sake of simplicity and some illustration purpose, we will put everything in one single jupyter notebook. It means that I will ignore any kind of OOP principles for a while :) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f41d3c",
   "metadata": {},
   "source": [
    "### Lib importation and data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba90796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #Natural Language Toolkit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ee088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to C:\\Users\\this\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\this\n",
      "[nltk_data]     pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ae62b",
   "metadata": {},
   "source": [
    "### Twitter sample data\n",
    "* The `twitter_samples` contains 5000 positive_tweets, 5000 negative_tweets, hence 10000 samples in total.\n",
    "* Each tweet is associated with a sentiment (a label). A positive tweet is labeled as 1 and a negative one is labeled as 0.\n",
    "* We use 80% data to train a model and 20% data for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6170b6",
   "metadata": {},
   "source": [
    "### Problem:\n",
    "We are in a typical framework for Sentiment Analysis where we would love to create some sort of algorithm to determine whether the sentiment of a sentence (a tweet in this case) is positive or negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35c4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1dd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set\n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg \n",
    "test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3663cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the numpy array of positive labels and negative labels.\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b987437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y.shape = (8000, 1)\n",
      "test_y.shape = (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape train and test sets\n",
    "print(\"train_y.shape = \" + str(train_y.shape))\n",
    "print(\"test_y.shape = \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f61223",
   "metadata": {},
   "source": [
    "Let's take a quick look into our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d484a5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tweet in train set is:  @UKBusinessLunch Hi we will be joining you again today :)\n"
     ]
    }
   ],
   "source": [
    "print('the tweet in train set is: ', train_x[108])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11a40c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 1001-th tweet in test set:  someone say thank u and goodbye to chris for me tomorrow pls :(\n"
     ]
    }
   ],
   "source": [
    "print('the 1001-th tweet in test set: ', test_x[1450])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a47a7b",
   "metadata": {},
   "source": [
    "## PART I - Data preprocessing\n",
    "Basic steps for data preprocessing:\n",
    "* Punctuation Removal\n",
    "* Lowering the Text\n",
    "* Tokenization i.e. split a tweet into words\n",
    "* Stop Word Removal: Stopwords are the commonly used words and are removed from the text as they do not add any value to the analysis\n",
    "* Stemming: Words are stemmed or diminished to their root/base form.  For example, ‚Äòprogrammer‚Äô, ‚Äòprogramming, ‚Äòprogram‚Äô are stemmed to ‚Äòprogram‚Äô\n",
    "\n",
    "Output: each tweet is transformed into a list of \"words\" (they are not 100% usual English words because of stemming operation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf6aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        :tweet: a string\n",
    "    Output:\n",
    "        :tweets_clean: a list of words containing the processed tweet\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True) #the tokenizer will downcase everything except for emoticons\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and   # remove stopwords\n",
    "                word not in string.punctuation): # remove punctuation\n",
    "            stem_word = stemmer.stem(word)\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc75ed04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\n",
      "['like', 'keep', 'love', 'custom', 'wait', 'long', 'hope', 'enjoy', 'happi', 'friday', 'lwwf', ':)']\n"
     ]
    }
   ],
   "source": [
    "print(train_x[6])\n",
    "print(process_tweet(train_x[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5cada7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@EllieVond @SkeletonSweets @Justin_Naito @justcallmerizzo No actually, you don't. Bye bye indeed. Go take your drama elsewhere. :)\n",
      "['actual', 'bye', 'bye', 'inde', 'go', 'take', 'drama', 'elsewher', ':)']\n"
     ]
    }
   ],
   "source": [
    "print(test_x[11])\n",
    "print(process_tweet(test_x[11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c438c0f2",
   "metadata": {},
   "source": [
    "## PART II - Feature engineering\n",
    "Basically, machine models are made by mathematical formulae, hence, they can only understand numerical structures. Hence, we have to extract from our text data (tweets) specific information (<b>feature</b>) which are numerically interpretable and are linked to our goal (Sentiment Analysis). <br>\n",
    "In the present Sentiment Analysis problem, we want to build a machine which is capable of reading a tweet and tell us whether this tweet has a positive or negative sentiment. <br>\n",
    "   \n",
    "* We build a frequency dictionary {(word, label): freq} which count the number of times (frequency) that the word is associated with the label. \n",
    "    * For example, ('happy', 1): 14 means that the word \"happy\" appears in positive tweets 14 times.\n",
    "* Given a list of tweets, we will extract two features and store them into a matrix\n",
    "    * The first feature is the number of positive words in a tweet.\n",
    "    * The second feature is the number of negative words in a tweet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b01c70",
   "metadata": {},
   "source": [
    "### PART II.1 - Build a frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5558a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(tweets, ys):\n",
    "    \"\"\" Build frequencies\n",
    "    Input:\n",
    "    tweets: a list of tweets\n",
    "    ys: an mx1 array with the sentiment label of each tweet (either 0 or 1)\n",
    "    Output:\n",
    "    freqs: a dictionary mapping each (word, sentiment) pair to its frequency\n",
    "    \"\"\"\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    # start with an empty dict and populate it by looping over all tweets\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a59a001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(freqs) = <class 'dict'>\n",
      "len(freqs) = 11397\n"
     ]
    }
   ],
   "source": [
    "# create frequency dictionary\n",
    "freqs = build_freqs(train_x, train_y)\n",
    "\n",
    "# check the output\n",
    "print(\"type(freqs) = \" + str(type(freqs)))\n",
    "print(\"len(freqs) = \" + str(len(freqs.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1809256",
   "metadata": {},
   "source": [
    "Let's take a look into our frequency dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87913866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('followfriday', 1.0): 23,\n",
       " ('top', 1.0): 30,\n",
       " ('engag', 1.0): 7,\n",
       " ('member', 1.0): 14,\n",
       " ('commun', 1.0): 27,\n",
       " ('week', 1.0): 72,\n",
       " (':)', 1.0): 2960,\n",
       " ('hey', 1.0): 60,\n",
       " ('jame', 1.0): 7,\n",
       " ('odd', 1.0): 2,\n",
       " (':/', 1.0): 5,\n",
       " ('pleas', 1.0): 81,\n",
       " ('call', 1.0): 27,\n",
       " ('contact', 1.0): 4,\n",
       " ('centr', 1.0): 1,\n",
       " ('02392441234', 1.0): 1,\n",
       " ('abl', 1.0): 6,\n",
       " ('assist', 1.0): 1,\n",
       " ('mani', 1.0): 28,\n",
       " ('thank', 1.0): 522,\n",
       " ('listen', 1.0): 15,\n",
       " ('last', 1.0): 39,\n",
       " ('night', 1.0): 55,\n",
       " ('bleed', 1.0): 2,\n",
       " ('amaz', 1.0): 41,\n",
       " ('track', 1.0): 5,\n",
       " ('scotland', 1.0): 2,\n",
       " ('congrat', 1.0): 15,\n",
       " ('yeaaah', 1.0): 1,\n",
       " ('yipppi', 1.0): 1,\n",
       " ('accnt', 1.0): 2,\n",
       " ('verifi', 1.0): 2,\n",
       " ('rqst', 1.0): 1,\n",
       " ('succeed', 1.0): 1,\n",
       " ('got', 1.0): 57,\n",
       " ('blue', 1.0): 8,\n",
       " ('tick', 1.0): 1,\n",
       " ('mark', 1.0): 1,\n",
       " ('fb', 1.0): 4,\n",
       " ('profil', 1.0): 2,\n",
       " ('15', 1.0): 4,\n",
       " ('day', 1.0): 187,\n",
       " ('one', 1.0): 92,\n",
       " ('irresist', 1.0): 2,\n",
       " ('flipkartfashionfriday', 1.0): 16,\n",
       " ('like', 1.0): 187,\n",
       " ('keep', 1.0): 55,\n",
       " ('love', 1.0): 336,\n",
       " ('custom', 1.0): 4,\n",
       " ('wait', 1.0): 55,\n",
       " ('long', 1.0): 27,\n",
       " ('hope', 1.0): 115,\n",
       " ('enjoy', 1.0): 61,\n",
       " ('happi', 1.0): 162,\n",
       " ('friday', 1.0): 91,\n",
       " ('lwwf', 1.0): 1,\n",
       " ('second', 1.0): 8,\n",
       " ('thought', 1.0): 21,\n",
       " ('‚Äô', 1.0): 17,\n",
       " ('enough', 1.0): 16,\n",
       " ('time', 1.0): 101,\n",
       " ('dd', 1.0): 1,\n",
       " ('new', 1.0): 114,\n",
       " ('short', 1.0): 6,\n",
       " ('enter', 1.0): 9,\n",
       " ('system', 1.0): 2,\n",
       " ('sheep', 1.0): 1,\n",
       " ('must', 1.0): 14,\n",
       " ('buy', 1.0): 10,\n",
       " ('jgh', 1.0): 4,\n",
       " ('go', 1.0): 123,\n",
       " ('bayan', 1.0): 1,\n",
       " (':d', 1.0): 523,\n",
       " ('bye', 1.0): 5,\n",
       " ('act', 1.0): 6,\n",
       " ('mischiev', 1.0): 1,\n",
       " ('etl', 1.0): 1,\n",
       " ('layer', 1.0): 1,\n",
       " ('in-hous', 1.0): 1,\n",
       " ('wareh', 1.0): 1,\n",
       " ('app', 1.0): 12,\n",
       " ('katamari', 1.0): 1,\n",
       " ('well', 1.0): 66,\n",
       " ('‚Ä¶', 1.0): 31,\n",
       " ('name', 1.0): 12,\n",
       " ('impli', 1.0): 1,\n",
       " (':p', 1.0): 105,\n",
       " ('influenc', 1.0): 16,\n",
       " ('big', 1.0): 28,\n",
       " ('...', 1.0): 228,\n",
       " ('juici', 1.0): 3,\n",
       " ('selfi', 1.0): 11,\n",
       " ('follow', 1.0): 385,\n",
       " ('u', 1.0): 204,\n",
       " ('back', 1.0): 139,\n",
       " ('perfect', 1.0): 17,\n",
       " ('alreadi', 1.0): 19,\n",
       " ('know', 1.0): 128,\n",
       " (\"what'\", 1.0): 14,\n",
       " ('great', 1.0): 135,\n",
       " ('opportun', 1.0): 17,\n",
       " ('junior', 1.0): 2,\n",
       " ('triathlet', 1.0): 1,\n",
       " ('age', 1.0): 2,\n",
       " ('12', 1.0): 5,\n",
       " ('13', 1.0): 5,\n",
       " ('gatorad', 1.0): 1,\n",
       " ('seri', 1.0): 4,\n",
       " ('get', 1.0): 166,\n",
       " ('entri', 1.0): 3,\n",
       " ('lay', 1.0): 3,\n",
       " ('greet', 1.0): 4,\n",
       " ('card', 1.0): 6,\n",
       " ('rang', 1.0): 2,\n",
       " ('print', 1.0): 4,\n",
       " ('today', 1.0): 91,\n",
       " ('job', 1.0): 34,\n",
       " (':-)', 1.0): 552,\n",
       " (\"friend'\", 1.0): 3,\n",
       " ('lunch', 1.0): 3,\n",
       " ('yummm', 1.0): 1,\n",
       " ('nostalgia', 1.0): 1,\n",
       " ('tb', 1.0): 1,\n",
       " ('ku', 1.0): 1,\n",
       " ('id', 1.0): 8,\n",
       " ('conflict', 1.0): 1,\n",
       " ('help', 1.0): 40,\n",
       " (\"here'\", 1.0): 20,\n",
       " ('screenshot', 1.0): 2,\n",
       " ('work', 1.0): 89,\n",
       " ('hi', 1.0): 154,\n",
       " ('liv', 1.0): 2,\n",
       " ('hello', 1.0): 49,\n",
       " ('need', 1.0): 62,\n",
       " ('someth', 1.0): 25,\n",
       " ('fm', 1.0): 2,\n",
       " ('twitter', 1.0): 25,\n",
       " ('‚Äî', 1.0): 22,\n",
       " ('sure', 1.0): 38,\n",
       " ('thing', 1.0): 48,\n",
       " ('dm', 1.0): 34,\n",
       " ('x', 1.0): 50,\n",
       " ('heard', 1.0): 9,\n",
       " ('four', 1.0): 5,\n",
       " ('season', 1.0): 5,\n",
       " ('pretti', 1.0): 17,\n",
       " ('dope', 1.0): 2,\n",
       " ('penthous', 1.0): 1,\n",
       " ('obv', 1.0): 1,\n",
       " ('gobigorgohom', 1.0): 1,\n",
       " ('fun', 1.0): 45,\n",
       " (\"y'all\", 1.0): 4,\n",
       " ('yeah', 1.0): 30,\n",
       " ('suppos', 1.0): 6,\n",
       " ('lol', 1.0): 48,\n",
       " ('chat', 1.0): 9,\n",
       " ('bit', 1.0): 16,\n",
       " ('youth', 1.0): 14,\n",
       " ('üíÖüèΩ', 1.0): 1,\n",
       " ('üíã', 1.0): 2,\n",
       " ('seen', 1.0): 6,\n",
       " ('year', 1.0): 33,\n",
       " ('rest', 1.0): 9,\n",
       " ('goe', 1.0): 4,\n",
       " ('quickli', 1.0): 3,\n",
       " ('bed', 1.0): 8,\n",
       " ('music', 1.0): 15,\n",
       " ('fix', 1.0): 6,\n",
       " ('dream', 1.0): 17,\n",
       " ('spiritu', 1.0): 1,\n",
       " ('ritual', 1.0): 1,\n",
       " ('festiv', 1.0): 7,\n",
       " ('n√©pal', 1.0): 1,\n",
       " ('begin', 1.0): 4,\n",
       " ('line-up', 1.0): 4,\n",
       " ('left', 1.0): 10,\n",
       " ('see', 1.0): 157,\n",
       " ('sarah', 1.0): 4,\n",
       " ('send', 1.0): 18,\n",
       " ('us', 1.0): 96,\n",
       " ('email', 1.0): 22,\n",
       " ('bitsy@bitdefender.com', 1.0): 1,\n",
       " ('asap', 1.0): 5,\n",
       " ('kik', 1.0): 16,\n",
       " ('hatessuc', 1.0): 1,\n",
       " ('32429', 1.0): 1,\n",
       " ('kikm', 1.0): 1,\n",
       " ('lgbt', 1.0): 2,\n",
       " ('tinder', 1.0): 1,\n",
       " ('nsfw', 1.0): 1,\n",
       " ('akua', 1.0): 1,\n",
       " ('cumshot', 1.0): 1,\n",
       " ('come', 1.0): 63,\n",
       " ('hous', 1.0): 5,\n",
       " ('nsn_supplement', 1.0): 1,\n",
       " ('effect', 1.0): 2,\n",
       " ('press', 1.0): 1,\n",
       " ('releas', 1.0): 11,\n",
       " ('distribut', 1.0): 1,\n",
       " ('result', 1.0): 2,\n",
       " ('link', 1.0): 14,\n",
       " ('remov', 1.0): 3,\n",
       " ('pressreleas', 1.0): 1,\n",
       " ('newsdistribut', 1.0): 1,\n",
       " ('bam', 1.0): 44,\n",
       " ('bestfriend', 1.0): 50,\n",
       " ('lot', 1.0): 80,\n",
       " ('warsaw', 1.0): 44,\n",
       " ('<3', 1.0): 119,\n",
       " ('x46', 1.0): 1,\n",
       " ('everyon', 1.0): 45,\n",
       " ('watch', 1.0): 32,\n",
       " ('documentari', 1.0): 1,\n",
       " ('earthl', 1.0): 1,\n",
       " ('youtub', 1.0): 8,\n",
       " ('support', 1.0): 25,\n",
       " ('buuut', 1.0): 1,\n",
       " ('oh', 1.0): 44,\n",
       " ('look', 1.0): 111,\n",
       " ('forward', 1.0): 20,\n",
       " ('visit', 1.0): 25,\n",
       " ('next', 1.0): 37,\n",
       " ('letsgetmessi', 1.0): 1,\n",
       " ('jo', 1.0): 1,\n",
       " ('make', 1.0): 70,\n",
       " ('feel', 1.0): 33,\n",
       " ('better', 1.0): 40,\n",
       " ('never', 1.0): 31,\n",
       " ('anyon', 1.0): 7,\n",
       " ('kpop', 1.0): 1,\n",
       " ('flesh', 1.0): 1,\n",
       " ('good', 1.0): 191,\n",
       " ('girl', 1.0): 34,\n",
       " ('best', 1.0): 49,\n",
       " ('wish', 1.0): 29,\n",
       " ('reason', 1.0): 10,\n",
       " ('epic', 1.0): 1,\n",
       " ('soundtrack', 1.0): 1,\n",
       " ('shout', 1.0): 11,\n",
       " ('ad', 1.0): 10,\n",
       " ('video', 1.0): 30,\n",
       " ('playlist', 1.0): 5,\n",
       " ('im', 1.0): 41,\n",
       " ('twitch', 1.0): 7,\n",
       " ('leagu', 1.0): 6,\n",
       " ('1', 1.0): 63,\n",
       " ('4', 1.0): 23,\n",
       " ('would', 1.0): 70,\n",
       " ('dear', 1.0): 15,\n",
       " ('jordan', 1.0): 1,\n",
       " ('okay', 1.0): 31,\n",
       " ('fake', 1.0): 1,\n",
       " ('gameplay', 1.0): 1,\n",
       " (';)', 1.0): 22,\n",
       " ('haha', 1.0): 44,\n",
       " ('kid', 1.0): 13,\n",
       " ('stuff', 1.0): 11,\n",
       " ('exactli', 1.0): 5,\n",
       " ('product', 1.0): 11,\n",
       " ('line', 1.0): 6,\n",
       " ('etsi', 1.0): 1,\n",
       " ('shop', 1.0): 12,\n",
       " ('check', 1.0): 39,\n",
       " ('boxroomcraft', 1.0): 1,\n",
       " ('vacat', 1.0): 5,\n",
       " ('recharg', 1.0): 1,\n",
       " ('normal', 1.0): 5,\n",
       " ('charger', 1.0): 2,\n",
       " ('asleep', 1.0): 7,\n",
       " ('talk', 1.0): 38,\n",
       " ('sooo', 1.0): 6,\n",
       " ('someon', 1.0): 29,\n",
       " ('text', 1.0): 12,\n",
       " ('ye', 1.0): 60,\n",
       " ('bet', 1.0): 6,\n",
       " ('fit', 1.0): 2,\n",
       " ('hear', 1.0): 24,\n",
       " ('speech', 1.0): 1,\n",
       " ('piti', 1.0): 2,\n",
       " ('green', 1.0): 2,\n",
       " ('garden', 1.0): 5,\n",
       " ('midnight', 1.0): 1,\n",
       " ('sun', 1.0): 6,\n",
       " ('beauti', 1.0): 45,\n",
       " ('canal', 1.0): 1,\n",
       " ('dasvidaniya', 1.0): 1,\n",
       " ('till', 1.0): 16,\n",
       " ('scout', 1.0): 1,\n",
       " ('sg', 1.0): 1,\n",
       " ('futur', 1.0): 9,\n",
       " ('wlan', 1.0): 1,\n",
       " ('pro', 1.0): 4,\n",
       " ('confer', 1.0): 1,\n",
       " ('asia', 1.0): 1,\n",
       " ('chang', 1.0): 20,\n",
       " ('lollipop', 1.0): 1,\n",
       " ('üç≠', 1.0): 1,\n",
       " ('nez', 1.0): 1,\n",
       " ('agnezmo', 1.0): 1,\n",
       " ('oley', 1.0): 1,\n",
       " ('mama', 1.0): 1,\n",
       " ('stand', 1.0): 6,\n",
       " ('stronger', 1.0): 1,\n",
       " ('god', 1.0): 14,\n",
       " ('misti', 1.0): 1,\n",
       " ('babi', 1.0): 17,\n",
       " ('cute', 1.0): 22,\n",
       " ('woohoo', 1.0): 3,\n",
       " (\"can't\", 1.0): 31,\n",
       " ('sign', 1.0): 9,\n",
       " ('yet', 1.0): 12,\n",
       " ('still', 1.0): 37,\n",
       " ('think', 1.0): 54,\n",
       " ('mka', 1.0): 5,\n",
       " ('liam', 1.0): 5,\n",
       " ('access', 1.0): 3,\n",
       " ('welcom', 1.0): 54,\n",
       " ('stat', 1.0): 51,\n",
       " ('arriv', 1.0): 57,\n",
       " ('unfollow', 1.0): 53,\n",
       " ('via', 1.0): 73,\n",
       " ('surpris', 1.0): 10,\n",
       " ('figur', 1.0): 5,\n",
       " ('happybirthdayemilybett', 1.0): 1,\n",
       " ('sweet', 1.0): 16,\n",
       " ('talent', 1.0): 4,\n",
       " ('2', 1.0): 41,\n",
       " ('plan', 1.0): 21,\n",
       " ('drain', 1.0): 1,\n",
       " ('gotta', 1.0): 4,\n",
       " ('timezon', 1.0): 1,\n",
       " ('parent', 1.0): 4,\n",
       " ('proud', 1.0): 11,\n",
       " ('least', 1.0): 14,\n",
       " ('mayb', 1.0): 17,\n",
       " ('sometim', 1.0): 11,\n",
       " ('grade', 1.0): 4,\n",
       " ('al', 1.0): 3,\n",
       " ('grand', 1.0): 4,\n",
       " ('manila_bro', 1.0): 1,\n",
       " ('chosen', 1.0): 1,\n",
       " ('let', 1.0): 70,\n",
       " ('around', 1.0): 14,\n",
       " ('..', 1.0): 100,\n",
       " ('side', 1.0): 13,\n",
       " ('world', 1.0): 23,\n",
       " ('eh', 1.0): 2,\n",
       " ('take', 1.0): 30,\n",
       " ('care', 1.0): 12,\n",
       " ('final', 1.0): 24,\n",
       " ('fuck', 1.0): 20,\n",
       " ('weekend', 1.0): 61,\n",
       " ('real', 1.0): 18,\n",
       " ('x45', 1.0): 1,\n",
       " ('join', 1.0): 21,\n",
       " ('hushedcallwithfraydo', 1.0): 1,\n",
       " ('gift', 1.0): 7,\n",
       " ('yeahhh', 1.0): 1,\n",
       " ('hushedpinwithsammi', 1.0): 2,\n",
       " ('event', 1.0): 8,\n",
       " ('might', 1.0): 21,\n",
       " ('luv', 1.0): 4,\n",
       " ('realli', 1.0): 66,\n",
       " ('appreci', 1.0): 28,\n",
       " ('share', 1.0): 41,\n",
       " ('wow', 1.0): 14,\n",
       " ('tom', 1.0): 6,\n",
       " ('3', 1.0): 27,\n",
       " ('gym', 1.0): 3,\n",
       " ('monday', 1.0): 7,\n",
       " ('invit', 1.0): 15,\n",
       " ('scope', 1.0): 5,\n",
       " ('friend', 1.0): 43,\n",
       " ('nude', 1.0): 1,\n",
       " ('sleep', 1.0): 35,\n",
       " ('birthday', 1.0): 53,\n",
       " ('want', 1.0): 71,\n",
       " ('t-shirt', 1.0): 2,\n",
       " ('cool', 1.0): 29,\n",
       " ('haw', 1.0): 1,\n",
       " ('phela', 1.0): 1,\n",
       " ('mom', 1.0): 7,\n",
       " ('obvious', 1.0): 1,\n",
       " ('princ', 1.0): 1,\n",
       " ('charm', 1.0): 1,\n",
       " ('stage', 1.0): 2,\n",
       " ('luck', 1.0): 26,\n",
       " ('tyler', 1.0): 1,\n",
       " ('hipster', 1.0): 1,\n",
       " ('glass', 1.0): 3,\n",
       " ('marti', 1.0): 2,\n",
       " ('glad', 1.0): 41,\n",
       " ('done', 1.0): 40,\n",
       " ('afternoon', 1.0): 7,\n",
       " ('read', 1.0): 28,\n",
       " ('kahfi', 1.0): 1,\n",
       " ('finish', 1.0): 15,\n",
       " ('ohmyg', 1.0): 1,\n",
       " ('yaya', 1.0): 3,\n",
       " ('dub', 1.0): 1,\n",
       " ('stalk', 1.0): 2,\n",
       " ('ig', 1.0): 3,\n",
       " ('gondooo', 1.0): 1,\n",
       " ('moo', 1.0): 2,\n",
       " ('tologooo', 1.0): 1,\n",
       " ('becom', 1.0): 8,\n",
       " ('detail', 1.0): 8,\n",
       " ('zzz', 1.0): 1,\n",
       " ('xx', 1.0): 33,\n",
       " ('physiotherapi', 1.0): 1,\n",
       " ('hashtag', 1.0): 3,\n",
       " ('üí™', 1.0): 1,\n",
       " ('monica', 1.0): 1,\n",
       " ('miss', 1.0): 17,\n",
       " ('sound', 1.0): 20,\n",
       " ('morn', 1.0): 68,\n",
       " (\"that'\", 1.0): 49,\n",
       " ('x43', 1.0): 1,\n",
       " ('definit', 1.0): 20,\n",
       " ('tri', 1.0): 34,\n",
       " ('tonight', 1.0): 15,\n",
       " ('took', 1.0): 7,\n",
       " ('advic', 1.0): 6,\n",
       " ('treviso', 1.0): 1,\n",
       " ('concert', 1.0): 23,\n",
       " ('citi', 1.0): 26,\n",
       " ('countri', 1.0): 22,\n",
       " ('start', 1.0): 56,\n",
       " ('fine', 1.0): 7,\n",
       " ('gorgeou', 1.0): 9,\n",
       " ('xo', 1.0): 2,\n",
       " ('oven', 1.0): 2,\n",
       " ('roast', 1.0): 1,\n",
       " ('garlic', 1.0): 1,\n",
       " ('oliv', 1.0): 1,\n",
       " ('oil', 1.0): 4,\n",
       " ('dri', 1.0): 4,\n",
       " ('tomato', 1.0): 1,\n",
       " ('basil', 1.0): 1,\n",
       " ('centuri', 1.0): 1,\n",
       " ('tuna', 1.0): 1,\n",
       " ('right', 1.0): 38,\n",
       " ('atchya', 1.0): 1,\n",
       " ('even', 1.0): 26,\n",
       " ('almost', 1.0): 8,\n",
       " ('chanc', 1.0): 3,\n",
       " ('cheer', 1.0): 18,\n",
       " ('po', 1.0): 3,\n",
       " ('ice', 1.0): 6,\n",
       " ('cream', 1.0): 6,\n",
       " ('agre', 1.0): 13,\n",
       " ('100', 1.0): 6,\n",
       " ('heheheh', 1.0): 2,\n",
       " ('that', 1.0): 10,\n",
       " ('point', 1.0): 11,\n",
       " ('stay', 1.0): 21,\n",
       " ('home', 1.0): 20,\n",
       " ('soon', 1.0): 38,\n",
       " ('promis', 1.0): 4,\n",
       " ('web', 1.0): 4,\n",
       " ('whatsapp', 1.0): 3,\n",
       " ('volta', 1.0): 1,\n",
       " ('funcionar', 1.0): 1,\n",
       " ('com', 1.0): 2,\n",
       " ('iphon', 1.0): 7,\n",
       " ('jailbroken', 1.0): 1,\n",
       " ('later', 1.0): 12,\n",
       " ('34', 1.0): 3,\n",
       " ('min', 1.0): 7,\n",
       " ('leia', 1.0): 1,\n",
       " ('appear', 1.0): 3,\n",
       " ('hologram', 1.0): 1,\n",
       " ('r2d2', 1.0): 1,\n",
       " ('w', 1.0): 16,\n",
       " ('messag', 1.0): 9,\n",
       " ('obi', 1.0): 1,\n",
       " ('wan', 1.0): 1,\n",
       " ('sit', 1.0): 7,\n",
       " ('luke', 1.0): 4,\n",
       " ('inter', 1.0): 1,\n",
       " ('ucl', 1.0): 1,\n",
       " ('arsen', 1.0): 2,\n",
       " ('small', 1.0): 2,\n",
       " ('team', 1.0): 24,\n",
       " ('pass', 1.0): 10,\n",
       " ('üöÇ', 1.0): 1,\n",
       " ('dewsburi', 1.0): 2,\n",
       " ('railway', 1.0): 1,\n",
       " ('station', 1.0): 4,\n",
       " ('dew', 1.0): 1,\n",
       " ('west', 1.0): 1,\n",
       " ('yorkshir', 1.0): 2,\n",
       " ('430', 1.0): 1,\n",
       " ('smh', 1.0): 2,\n",
       " ('9:25', 1.0): 1,\n",
       " ('live', 1.0): 23,\n",
       " ('strang', 1.0): 4,\n",
       " ('imagin', 1.0): 5,\n",
       " ('megan', 1.0): 1,\n",
       " ('masaantoday', 1.0): 4,\n",
       " ('a4', 1.0): 3,\n",
       " ('shweta', 1.0): 1,\n",
       " ('tripathi', 1.0): 1,\n",
       " ('5', 1.0): 15,\n",
       " ('20', 1.0): 5,\n",
       " ('kurta', 1.0): 3,\n",
       " ('half', 1.0): 6,\n",
       " ('number', 1.0): 11,\n",
       " ('wsalelov', 1.0): 14,\n",
       " ('ah', 1.0): 12,\n",
       " ('larri', 1.0): 3,\n",
       " ('anyway', 1.0): 14,\n",
       " ('kinda', 1.0): 12,\n",
       " ('goood', 1.0): 1,\n",
       " ('life', 1.0): 36,\n",
       " ('enn', 1.0): 1,\n",
       " ('could', 1.0): 25,\n",
       " ('warmup', 1.0): 1,\n",
       " ('15th', 1.0): 2,\n",
       " ('bath', 1.0): 6,\n",
       " ('dum', 1.0): 2,\n",
       " ('andar', 1.0): 1,\n",
       " ('ram', 1.0): 1,\n",
       " ('sampath', 1.0): 1,\n",
       " ('sona', 1.0): 1,\n",
       " ('mohapatra', 1.0): 1,\n",
       " ('samantha', 1.0): 1,\n",
       " ('edward', 1.0): 1,\n",
       " ('mein', 1.0): 1,\n",
       " ('tulan', 1.0): 1,\n",
       " ('razi', 1.0): 2,\n",
       " ('wah', 1.0): 2,\n",
       " ('josh', 1.0): 1,\n",
       " ('alway', 1.0): 48,\n",
       " ('smile', 1.0): 47,\n",
       " ('pictur', 1.0): 7,\n",
       " ('16.20', 1.0): 1,\n",
       " ('giveitup', 1.0): 1,\n",
       " ('given', 1.0): 3,\n",
       " ('ga', 1.0): 3,\n",
       " ('subsidi', 1.0): 1,\n",
       " ('initi', 1.0): 2,\n",
       " ('propos', 1.0): 3,\n",
       " ('delight', 1.0): 4,\n",
       " ('yesterday', 1.0): 4,\n",
       " ('x42', 1.0): 1,\n",
       " ('lmaoo', 1.0): 2,\n",
       " ('song', 1.0): 16,\n",
       " ('ever', 1.0): 19,\n",
       " ('shall', 1.0): 5,\n",
       " ('littl', 1.0): 29,\n",
       " ('throwback', 1.0): 3,\n",
       " ('outli', 1.0): 1,\n",
       " ('island', 1.0): 2,\n",
       " ('cheung', 1.0): 1,\n",
       " ('chau', 1.0): 1,\n",
       " ('mui', 1.0): 1,\n",
       " ('wo', 1.0): 1,\n",
       " ('total', 1.0): 6,\n",
       " ('differ', 1.0): 10,\n",
       " ('kfckitchentour', 1.0): 2,\n",
       " ('kitchen', 1.0): 3,\n",
       " ('clean', 1.0): 1,\n",
       " ('cusp', 1.0): 1,\n",
       " ('test', 1.0): 7,\n",
       " ('water', 1.0): 7,\n",
       " ('reward', 1.0): 1,\n",
       " ('arummzz', 1.0): 2,\n",
       " (\"let'\", 1.0): 20,\n",
       " ('drive', 1.0): 9,\n",
       " ('travel', 1.0): 19,\n",
       " ('yogyakarta', 1.0): 3,\n",
       " ('jeep', 1.0): 3,\n",
       " ('indonesia', 1.0): 3,\n",
       " ('instamood', 1.0): 3,\n",
       " ('wanna', 1.0): 23,\n",
       " ('skype', 1.0): 3,\n",
       " ('may', 1.0): 16,\n",
       " ('nice', 1.0): 71,\n",
       " ('friendli', 1.0): 1,\n",
       " ('pretend', 1.0): 2,\n",
       " ('film', 1.0): 8,\n",
       " ('congratul', 1.0): 9,\n",
       " ('winner', 1.0): 3,\n",
       " ('cheesydelight', 1.0): 1,\n",
       " ('contest', 1.0): 5,\n",
       " ('address', 1.0): 8,\n",
       " ('guy', 1.0): 48,\n",
       " ('market', 1.0): 5,\n",
       " ('24/7', 1.0): 1,\n",
       " ('regret', 1.0): 4,\n",
       " ('14', 1.0): 1,\n",
       " ('hour', 1.0): 24,\n",
       " ('leav', 1.0): 12,\n",
       " ('without', 1.0): 9,\n",
       " ('delay', 1.0): 1,\n",
       " ('actual', 1.0): 13,\n",
       " ('easi', 1.0): 7,\n",
       " ('guess', 1.0): 8,\n",
       " ('train', 1.0): 7,\n",
       " ('wd', 1.0): 1,\n",
       " ('shift', 1.0): 4,\n",
       " ('engin', 1.0): 1,\n",
       " ('etc', 1.0): 2,\n",
       " ('sunburn', 1.0): 1,\n",
       " ('peel', 1.0): 2,\n",
       " ('blog', 1.0): 27,\n",
       " ('huge', 1.0): 9,\n",
       " ('warm', 1.0): 4,\n",
       " ('‚òÜ', 1.0): 3,\n",
       " ('complet', 1.0): 10,\n",
       " ('triangl', 1.0): 2,\n",
       " ('northern', 1.0): 1,\n",
       " ('ireland', 1.0): 2,\n",
       " ('sight', 1.0): 1,\n",
       " ('smthng', 1.0): 2,\n",
       " ('fr', 1.0): 3,\n",
       " ('hug', 1.0): 11,\n",
       " ('xoxo', 1.0): 3,\n",
       " ('uu', 1.0): 1,\n",
       " ('jaann', 1.0): 1,\n",
       " ('topnewfollow', 1.0): 2,\n",
       " ('connect', 1.0): 13,\n",
       " ('wonder', 1.0): 26,\n",
       " ('made', 1.0): 38,\n",
       " ('fluffi', 1.0): 1,\n",
       " ('insid', 1.0): 7,\n",
       " ('pirouett', 1.0): 1,\n",
       " ('moos', 1.0): 1,\n",
       " ('trip', 1.0): 12,\n",
       " ('philli', 1.0): 1,\n",
       " ('decemb', 1.0): 2,\n",
       " ('dude', 1.0): 6,\n",
       " ('x41', 1.0): 1,\n",
       " ('question', 1.0): 15,\n",
       " ('flaw', 1.0): 1,\n",
       " ('pain', 1.0): 8,\n",
       " ('negat', 1.0): 1,\n",
       " ('strength', 1.0): 2,\n",
       " ('went', 1.0): 10,\n",
       " ('solo', 1.0): 4,\n",
       " ('move', 1.0): 9,\n",
       " ('fav', 1.0): 11,\n",
       " ('nirvana', 1.0): 1,\n",
       " ('smell', 1.0): 2,\n",
       " ('teen', 1.0): 3,\n",
       " ('spirit', 1.0): 1,\n",
       " ('rip', 1.0): 3,\n",
       " ('ami', 1.0): 4,\n",
       " ('winehous', 1.0): 1,\n",
       " ('coupl', 1.0): 5,\n",
       " ('tomhiddleston', 1.0): 1,\n",
       " ('elizabetholsen', 1.0): 1,\n",
       " ('yaytheylookgreat', 1.0): 1,\n",
       " ('goodnight', 1.0): 18,\n",
       " ('vid', 1.0): 8,\n",
       " ('wake', 1.0): 10,\n",
       " ('gonna', 1.0): 16,\n",
       " ('shoot', 1.0): 5,\n",
       " ('itti', 1.0): 2,\n",
       " ('bitti', 1.0): 2,\n",
       " ('teeni', 1.0): 2,\n",
       " ('bikini', 1.0): 3,\n",
       " ('much', 1.0): 73,\n",
       " ('4th', 1.0): 4,\n",
       " ('togeth', 1.0): 6,\n",
       " ('end', 1.0): 13,\n",
       " ('xfile', 1.0): 1,\n",
       " ('content', 1.0): 3,\n",
       " ('rain', 1.0): 18,\n",
       " ('fabul', 1.0): 4,\n",
       " ('fantast', 1.0): 9,\n",
       " ('‚ô°', 1.0): 12,\n",
       " ('jb', 1.0): 1,\n",
       " ('forev', 1.0): 5,\n",
       " ('belieb', 1.0): 3,\n",
       " ('nighti', 1.0): 1,\n",
       " ('bug', 1.0): 2,\n",
       " ('bite', 1.0): 1,\n",
       " ('bracelet', 1.0): 2,\n",
       " ('idea', 1.0): 24,\n",
       " ('foundri', 1.0): 1,\n",
       " ('game', 1.0): 23,\n",
       " ('sens', 1.0): 6,\n",
       " ('pic', 1.0): 21,\n",
       " ('ef', 1.0): 1,\n",
       " ('phone', 1.0): 16,\n",
       " ('woot', 1.0): 2,\n",
       " ('derek', 1.0): 1,\n",
       " ('use', 1.0): 32,\n",
       " ('parkshar', 1.0): 1,\n",
       " ('gloucestershir', 1.0): 1,\n",
       " ('aaaahhh', 1.0): 1,\n",
       " ('man', 1.0): 16,\n",
       " ('traffic', 1.0): 2,\n",
       " ('stress', 1.0): 4,\n",
       " ('reliev', 1.0): 1,\n",
       " (\"how'r\", 1.0): 1,\n",
       " ('arbeloa', 1.0): 1,\n",
       " ('turn', 1.0): 14,\n",
       " ('17', 1.0): 2,\n",
       " ('omg', 1.0): 13,\n",
       " ('say', 1.0): 43,\n",
       " ('europ', 1.0): 1,\n",
       " ('rise', 1.0): 2,\n",
       " ('find', 1.0): 22,\n",
       " ('hard', 1.0): 9,\n",
       " ('believ', 1.0): 7,\n",
       " ('uncount', 1.0): 1,\n",
       " ('coz', 1.0): 2,\n",
       " ('unlimit', 1.0): 1,\n",
       " ('cours', 1.0): 11,\n",
       " ('teamposit', 1.0): 1,\n",
       " ('aldub', 1.0): 2,\n",
       " ('‚òï', 1.0): 3,\n",
       " ('rita', 1.0): 2,\n",
       " ('info', 1.0): 11,\n",
       " ('way', 1.0): 34,\n",
       " ('boy', 1.0): 13,\n",
       " ('x40', 1.0): 1,\n",
       " ('true', 1.0): 19,\n",
       " ('sethi', 1.0): 2,\n",
       " ('high', 1.0): 6,\n",
       " ('exe', 1.0): 1,\n",
       " ('skeem', 1.0): 1,\n",
       " ('saam', 1.0): 1,\n",
       " ('peopl', 1.0): 43,\n",
       " ('polit', 1.0): 2,\n",
       " ('izzat', 1.0): 1,\n",
       " ('wese', 1.0): 1,\n",
       " ('trust', 1.0): 7,\n",
       " ('khawateen', 1.0): 1,\n",
       " ('k', 1.0): 8,\n",
       " ('sath', 1.0): 2,\n",
       " ('mana', 1.0): 1,\n",
       " ('kar', 1.0): 1,\n",
       " ('deya', 1.0): 1,\n",
       " ('sort', 1.0): 7,\n",
       " ('smart', 1.0): 5,\n",
       " ('hair', 1.0): 7,\n",
       " ('tbh', 1.0): 5,\n",
       " ('jacob', 1.0): 2,\n",
       " ('g', 1.0): 8,\n",
       " ('upgrad', 1.0): 2,\n",
       " ('tee', 1.0): 3,\n",
       " ('famili', 1.0): 14,\n",
       " ('person', 1.0): 14,\n",
       " ('two', 1.0): 15,\n",
       " ('convers', 1.0): 6,\n",
       " ('onlin', 1.0): 4,\n",
       " ('mclaren', 1.0): 1,\n",
       " ('fridayfeel', 1.0): 5,\n",
       " ('tgif', 1.0): 8,\n",
       " ('squar', 1.0): 1,\n",
       " ('enix', 1.0): 1,\n",
       " ('bissmillah', 1.0): 1,\n",
       " ('ya', 1.0): 19,\n",
       " ('allah', 1.0): 3,\n",
       " ('socent', 1.0): 1,\n",
       " ('startup', 1.0): 2,\n",
       " ('drop', 1.0): 9,\n",
       " ('your', 1.0): 3,\n",
       " ('arnd', 1.0): 1,\n",
       " ('town', 1.0): 3,\n",
       " ('basic', 1.0): 4,\n",
       " ('piss', 1.0): 2,\n",
       " ('cup', 1.0): 4,\n",
       " ('also', 1.0): 29,\n",
       " ('terribl', 1.0): 2,\n",
       " ('complic', 1.0): 1,\n",
       " ('discuss', 1.0): 2,\n",
       " ('snapchat', 1.0): 31,\n",
       " ('lynettelow', 1.0): 1,\n",
       " ('kikmenow', 1.0): 2,\n",
       " ('snapm', 1.0): 1,\n",
       " ('hot', 1.0): 20,\n",
       " ('amazon', 1.0): 1,\n",
       " ('kikmeguy', 1.0): 2,\n",
       " ('defin', 1.0): 2,\n",
       " ('grow', 1.0): 6,\n",
       " ('sport', 1.0): 4,\n",
       " ('rt', 1.0): 9,\n",
       " ('rakyat', 1.0): 1,\n",
       " ('write', 1.0): 11,\n",
       " ('sinc', 1.0): 11,\n",
       " ('mention', 1.0): 18,\n",
       " ('fli', 1.0): 5,\n",
       " ('fish', 1.0): 4,\n",
       " ('promot', 1.0): 3,\n",
       " ('post', 1.0): 16,\n",
       " ('cyber', 1.0): 1,\n",
       " ('ourdaughtersourprid', 1.0): 3,\n",
       " ('mypapamyprid', 1.0): 2,\n",
       " ('papa', 1.0): 1,\n",
       " ('coach', 1.0): 2,\n",
       " ('posit', 1.0): 3,\n",
       " ('kha', 1.0): 1,\n",
       " ('atleast', 1.0): 2,\n",
       " ('x39', 1.0): 1,\n",
       " ('mango', 1.0): 1,\n",
       " (\"lassi'\", 1.0): 1,\n",
       " (\"monty'\", 1.0): 1,\n",
       " ('marvel', 1.0): 2,\n",
       " ('though', 1.0): 16,\n",
       " ('suspect', 1.0): 3,\n",
       " ('meant', 1.0): 2,\n",
       " ('24', 1.0): 3,\n",
       " ('hr', 1.0): 2,\n",
       " ('touch', 1.0): 7,\n",
       " ('kepler', 1.0): 3,\n",
       " ('452b', 1.0): 4,\n",
       " ('chalna', 1.0): 1,\n",
       " ('hai', 1.0): 7,\n",
       " ('thankyou', 1.0): 12,\n",
       " ('hazel', 1.0): 1,\n",
       " ('food', 1.0): 10,\n",
       " ('brooklyn', 1.0): 1,\n",
       " ('pta', 1.0): 2,\n",
       " ('awak', 1.0): 8,\n",
       " ('okayi', 1.0): 2,\n",
       " ('awww', 1.0): 12,\n",
       " ('ha', 1.0): 18,\n",
       " ('doc', 1.0): 1,\n",
       " ('splendid', 1.0): 1,\n",
       " ('spam', 1.0): 1,\n",
       " ('folder', 1.0): 1,\n",
       " ('amount', 1.0): 1,\n",
       " ('nigeria', 1.0): 1,\n",
       " ('claim', 1.0): 1,\n",
       " ('rted', 1.0): 1,\n",
       " ('leg', 1.0): 3,\n",
       " ('hurt', 1.0): 4,\n",
       " ('bad', 1.0): 14,\n",
       " ('mine', 1.0): 11,\n",
       " ('saturday', 1.0): 5,\n",
       " ('thaaank', 1.0): 1,\n",
       " ('puhon', 1.0): 1,\n",
       " ('happinesss', 1.0): 1,\n",
       " ('tnc', 1.0): 1,\n",
       " ('prior', 1.0): 1,\n",
       " ('notif', 1.0): 2,\n",
       " ('probabl', 1.0): 8,\n",
       " ('funni', 1.0): 16,\n",
       " ('2:22', 1.0): 1,\n",
       " ('fat', 1.0): 1,\n",
       " ('co', 1.0): 1,\n",
       " ('ate', 1.0): 4,\n",
       " ('yuna', 1.0): 2,\n",
       " ('tamesid', 1.0): 1,\n",
       " ('¬¥', 1.0): 3,\n",
       " ('googl', 1.0): 5,\n",
       " ('account', 1.0): 17,\n",
       " ('scouser', 1.0): 1,\n",
       " ('everyth', 1.0): 10,\n",
       " ('zoe', 1.0): 1,\n",
       " ('mate', 1.0): 5,\n",
       " ('liter', 1.0): 6,\n",
       " ('samee', 1.0): 1,\n",
       " ('edgar', 1.0): 1,\n",
       " ('updat', 1.0): 12,\n",
       " ('log', 1.0): 3,\n",
       " ('bring', 1.0): 14,\n",
       " ('abe', 1.0): 1,\n",
       " ('meet', 1.0): 26,\n",
       " ('x38', 1.0): 1,\n",
       " ('sigh', 1.0): 3,\n",
       " ('dreamili', 1.0): 1,\n",
       " ('pout', 1.0): 1,\n",
       " ('eye', 1.0): 12,\n",
       " ('quacketyquack', 1.0): 6,\n",
       " ('happen', 1.0): 13,\n",
       " ('phil', 1.0): 1,\n",
       " ('em', 1.0): 2,\n",
       " ('del', 1.0): 1,\n",
       " ('rodder', 1.0): 1,\n",
       " ('els', 1.0): 8,\n",
       " ('play', 1.0): 37,\n",
       " ('newest', 1.0): 1,\n",
       " ('gamejam', 1.0): 1,\n",
       " ('irish', 1.0): 2,\n",
       " ('literatur', 1.0): 2,\n",
       " ('inaccess', 1.0): 2,\n",
       " (\"kareena'\", 1.0): 2,\n",
       " ('fan', 1.0): 21,\n",
       " ('brain', 1.0): 10,\n",
       " ('dot', 1.0): 8,\n",
       " ('braindot', 1.0): 8,\n",
       " ('fair', 1.0): 4,\n",
       " ('rush', 1.0): 1,\n",
       " ('either', 1.0): 10,\n",
       " ('brandi', 1.0): 1,\n",
       " ('18', 1.0): 5,\n",
       " ('carniv', 1.0): 1,\n",
       " ('men', 1.0): 8,\n",
       " ('put', 1.0): 11,\n",
       " ('mask', 1.0): 2,\n",
       " ('xavier', 1.0): 1,\n",
       " ('forneret', 1.0): 1,\n",
       " ('jennif', 1.0): 1,\n",
       " ('site', 1.0): 7,\n",
       " ('free', 1.0): 32,\n",
       " ('50.000', 1.0): 3,\n",
       " ('8', 1.0): 11,\n",
       " ('ball', 1.0): 7,\n",
       " ('pool', 1.0): 5,\n",
       " ('coin', 1.0): 5,\n",
       " ('edit', 1.0): 6,\n",
       " ('trish', 1.0): 1,\n",
       " ('‚ô•', 1.0): 13,\n",
       " ('grate', 1.0): 5,\n",
       " ('three', 1.0): 8,\n",
       " ('comment', 1.0): 8,\n",
       " ('wakeup', 1.0): 1,\n",
       " ('besid', 1.0): 2,\n",
       " ('dirti', 1.0): 2,\n",
       " ('sex', 1.0): 4,\n",
       " ('lmaooo', 1.0): 1,\n",
       " ('üò§', 1.0): 2,\n",
       " ('loui', 1.0): 4,\n",
       " ('throw', 1.0): 3,\n",
       " ('caus', 1.0): 11,\n",
       " ('inspir', 1.0): 6,\n",
       " ('ff', 1.0): 40,\n",
       " ('twoof', 1.0): 3,\n",
       " ('gr8', 1.0): 1,\n",
       " ('wkend', 1.0): 3,\n",
       " ('kind', 1.0): 22,\n",
       " ('exhaust', 1.0): 2,\n",
       " ('word', 1.0): 17,\n",
       " ('cheltenham', 1.0): 1,\n",
       " ('area', 1.0): 4,\n",
       " ('kale', 1.0): 1,\n",
       " ('crisp', 1.0): 1,\n",
       " ('ruin', 1.0): 5,\n",
       " ('x37', 1.0): 1,\n",
       " ('open', 1.0): 12,\n",
       " ('worldwid', 1.0): 2,\n",
       " ('outta', 1.0): 1,\n",
       " ('sfvbeta', 1.0): 1,\n",
       " ('vantast', 1.0): 1,\n",
       " ('xcylin', 1.0): 1,\n",
       " ('bundl', 1.0): 1,\n",
       " ('show', 1.0): 20,\n",
       " ('internet', 1.0): 2,\n",
       " ('price', 1.0): 3,\n",
       " ('realisticli', 1.0): 1,\n",
       " ('pay', 1.0): 8,\n",
       " ('net', 1.0): 1,\n",
       " ('educ', 1.0): 1,\n",
       " ('power', 1.0): 6,\n",
       " ('weapon', 1.0): 1,\n",
       " ('nelson', 1.0): 1,\n",
       " ('mandela', 1.0): 1,\n",
       " ('recent', 1.0): 8,\n",
       " ('j', 1.0): 2,\n",
       " ('chenab', 1.0): 1,\n",
       " ('flow', 1.0): 5,\n",
       " ('pakistan', 1.0): 1,\n",
       " ('incredibleindia', 1.0): 1,\n",
       " ('teenchoic', 1.0): 7,\n",
       " ('choiceinternationalartist', 1.0): 7,\n",
       " ('superjunior', 1.0): 7,\n",
       " ('caught', 1.0): 4,\n",
       " ('first', 1.0): 41,\n",
       " ('salmon', 1.0): 1,\n",
       " ('super-blend', 1.0): 1,\n",
       " ('project', 1.0): 6,\n",
       " ('youth@bipolaruk.org.uk', 1.0): 1,\n",
       " ('awesom', 1.0): 35,\n",
       " ('stream', 1.0): 12,\n",
       " ('artist', 1.0): 2,\n",
       " ('alma', 1.0): 1,\n",
       " ('mater', 1.0): 1,\n",
       " ('highschoolday', 1.0): 1,\n",
       " ('clientvisit', 1.0): 1,\n",
       " ('faith', 1.0): 3,\n",
       " ('christian', 1.0): 1,\n",
       " ('school', 1.0): 9,\n",
       " ('lizaminnelli', 1.0): 1,\n",
       " ('upcom', 1.0): 2,\n",
       " ('uk', 1.0): 4,\n",
       " ('üòÑ', 1.0): 3,\n",
       " ('singl', 1.0): 4,\n",
       " ('hill', 1.0): 4,\n",
       " ('everi', 1.0): 23,\n",
       " ('beat', 1.0): 7,\n",
       " ('wrong', 1.0): 9,\n",
       " ('readi', 1.0): 22,\n",
       " ('natur', 1.0): 1,\n",
       " ('pefumeri', 1.0): 1,\n",
       " ('workshop', 1.0): 2,\n",
       " ('neal', 1.0): 1,\n",
       " ('yard', 1.0): 1,\n",
       " ('covent', 1.0): 1,\n",
       " ('tomorrow', 1.0): 31,\n",
       " ('fback', 1.0): 26,\n",
       " ('indo', 1.0): 1,\n",
       " ('harmo', 1.0): 1,\n",
       " ('americano', 1.0): 1,\n",
       " ('rememb', 1.0): 9,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899199fe",
   "metadata": {},
   "source": [
    "### PART II.2 - Feature extraction\n",
    "Implement extract_features function:\n",
    "* This function takes in a single tweet.\n",
    "* Process the tweet using `process_tweet` function and save the list of tweet words.\n",
    "* Loop through each word in the list of processed words\n",
    "    * For each word, check the 'freqs' dictionary for the count when that word has a positive '1' label. (value associated with the key (word, 1.0)\n",
    "    * Do the same for the count for when the word is associated with the negative label '0'. (value associated with the key (word, 0.0).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2c2befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a list of words for one tweet\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "    Output: \n",
    "        x: a feature vector of dimension (1,3)\n",
    "    '''\n",
    "    # process_tweet tokenizes, stems, and removes stopwords\n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        if (word, 1) in freqs.keys():\n",
    "            x[0,1] += freqs[(word, 1)]\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        if (word, 0) in freqs.keys():\n",
    "            x[0,2] += freqs[(word, 0)]\n",
    "        \n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37002bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jgh , but we have to go to Bayan :D bye'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "578372bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 656., 189.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_features(train_x[8], freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11568592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jgh', 'go', 'bayan', ':d', 'bye']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_tweet(train_x[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52d0d5",
   "metadata": {},
   "source": [
    "## Part III - Logistic regression - Custom-built\n",
    "\n",
    "### Part III.1 - Sigmoid\n",
    "You will learn to use logistic regression for text classification. \n",
    "* The sigmoid function is defined as: \n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n",
    "\n",
    "It maps the input 'z' to a value that ranges between 0 and 1, and so it can be treated as a probability. \n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='./sigmoid_function.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:800px;height:400px;\"/> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52e5497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z): \n",
    "    '''\n",
    "    Input:\n",
    "        z: is the input (can be a scalar or an array)\n",
    "    Output:\n",
    "        h: the sigmoid of z\n",
    "    ''' \n",
    "    h = 1. / (1. + np.exp(-z))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53361390",
   "metadata": {},
   "source": [
    "### PART III.2 - Logistic regression\n",
    "\n",
    "Logistic regression takes a regular linear regression, and applies a sigmoid to the output of the linear regression.\n",
    "\n",
    "#### Regression (logit)\n",
    "$$z = w_0 + w_1 x_1 + w_2 x_2 + \\ldots + w_n x_n$$\n",
    "In our case $n$ is equal to $2$.\n",
    "\n",
    "#### The prediction\n",
    "$$ y_{\\text{pred}} = \\sigma(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
    "\n",
    "#### Loss function (binary log-loss)\n",
    "$$J(w) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (y_{\\text{pred}}^{(i)}) + (1-y^{(i)})\\log (1-y_{\\text{pred}}^{(i)})$$\n",
    "* $w = (w_0, w_1, w_2)$ is model parameters\n",
    "* $m$ is the number of training examples\n",
    "* $y^{(i)}$ is the actual label of training example 'i'.\n",
    "* $h(z^{(i)})$ is the model's prediction for the training example 'i'.\n",
    "\n",
    "The goal of a training process is to minimize the loss function $J(w)$ on the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daef631",
   "metadata": {},
   "source": [
    "#### Gradient descent\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='./gradient_descent.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:800px;height:400px;\"/> </div>\n",
    "\n",
    "Compute the gradient\n",
    "$$\\dfrac{\\partial J}{\\partial w_j} (w) = \\frac{1}{m} \\sum_{i=1}^m(y_{\\text{pred}}^{(i)}-y^{(i)})x^{(i)}_j$$\n",
    "Update the weights $w$\n",
    "$$w_j = w_j - \\alpha \\dfrac{\\partial J}{\\partial w_j} (w)$$\n",
    "\n",
    "#### Matrix form and implementation\n",
    "* $w$ has dimensions (n+1, 1), where 'n' is the number of features, and there is one more element for the bias term $w_0$\n",
    "* The 'logits', 'z', are calculated by multiplying the feature matrix $X$ with the weight vector $w$ i.e. $z = Xw$\n",
    "    * $X$ has dimensions (m, n+1) \n",
    "    * $w$: has dimensions (n+1, 1)\n",
    "    * $z$: has dimensions (m, 1)\n",
    "* The prediction $y_{\\text{pred}}$, is calculated by applying the sigmoid to $z$, and has dimensions (m,1).\n",
    "* The cost function $J$ in its vector form\n",
    "$$J = -\\frac{1}{m} \\times \\left(y^T \\cdot log(y_{\\text{pred}}) + (1-y)^T \\cdot log(1 - y_{\\text{pred}}) \\right)$$\n",
    "* The update of $w$ is also vectorized\n",
    "$$w = w - \\frac{\\alpha}{m} \\times \\left( X^T \\cdot \\left(y_{\\text{pred}} - y\\right) \\right)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ce09e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gradient_descent_logistic(x, y, theta, alpha, num_iters):\n",
    "    '''\n",
    "    Input:\n",
    "        x: matrix of features which is (m,n+1)\n",
    "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
    "        theta: weight vector of dimension (n+1,1)\n",
    "        alpha: learning rate\n",
    "        num_iters: number of iterations you want to train your model for\n",
    "    Output:\n",
    "        J: the final cost\n",
    "        theta: your final weight vector\n",
    "    Hint: you might want to print the cost to make sure that it is going down.\n",
    "    '''\n",
    "    # get 'm', the number of rows in matrix X\n",
    "    m = len(x)\n",
    "    losses = []\n",
    "    for i in range(0, num_iters):\n",
    "        \n",
    "        # get z, the dot product of x and theta\n",
    "        z = np.dot(x, theta)\n",
    "        \n",
    "        # get the sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # calculate the cost function\n",
    "        # J = - (np.dot(y.T, np.log(h)) + np.dot((1-y).T, np.log(1-h))) / float(m)\n",
    "        # Adjust the cost function to avoid log(0)\n",
    "        epsilon = 1e-5  # small constant to avoid log(0)\n",
    "        J = - (np.dot(y.T, np.log(h + epsilon)) + np.dot((1-y).T, np.log(1-h + epsilon))) / float(m)\n",
    "        losses.append(float(J))\n",
    "        # update the weights theta\n",
    "        theta = theta - (alpha * np.dot(x.T, (h-y))) / float(m)\n",
    "    \n",
    "    J = float(J)\n",
    "    \n",
    "    # plot the loss function\n",
    "    iter_list = np.arange(1, num_iters + 1, 1)\n",
    "    plt.plot(iter_list, losses, color='green', label='loss')\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ee8694",
   "metadata": {},
   "source": [
    "#### The line 'J = - (np.dot(y.T, np.log(h)) + np.dot((1-y).T, np.log(1-h))) / float(m)' in the code could make 'divided by zero' error because when the number of iterations is large, theta becomes very large or very small impact to the logit z also be very large or very small and make log(h) or log(1-h) becomes log(0),which is the main reason for this error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd0fdd",
   "metadata": {},
   "source": [
    "#### Recommendation for fixed:\n",
    "\n",
    "* **Scalar Conversion:** Convert the cost $J$ to a scalar with `.item()` before appending it to the losses list. This guarantees that $J$ is handled as a single numeric value, which can be important for later calculations or comparisons.\n",
    "* **Epsilon in Logarithm:** Add a small epsilon inside the log function to prevent undefined operations such as taking the logarithm of 0 and to keep values safely away from 0 or 1.\n",
    "* **Adjust Learning Rate:** Slightly increase the learning rate to speed up convergence and reduce the chance of accumulating numerical errors over many iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8415d99",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "```\n",
    "The cost after training is 0.67094970.\n",
    "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d12be2",
   "metadata": {},
   "source": [
    "### PART III.3 - Logistic Regression training\n",
    "\n",
    "* Stack the features for all training examples into a matrix X. \n",
    "* Call gradient_descent_logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a7e7a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\2761024099.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  losses.append(float(J))\n",
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\2761024099.py:36: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  J = float(J)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.10156780.\n",
      "The resulting vector of weights is [np.float64(3e-07), np.float64(0.00127323), np.float64(-0.001111)]\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "J, w = gradient_descent_logistic(X, Y, np.zeros((3, 1)), 1e-9, 10000)\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(w)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d9b17",
   "metadata": {},
   "source": [
    "#### Write a function to predict whether a tweet is positive or negative.\n",
    "* Given a tweet, process it, then extract the features.\n",
    "* Apply the model's learned weights $w$ on the features to get the logits.\n",
    "* Apply the sigmoid to the logits to get the prediction (a value between 0 and 1).\n",
    "\n",
    "$$y_{pred} = \\sigma(X \\cdot w)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4a14549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet(tweet, freqs, theta):\n",
    "    '''\n",
    "    Input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    Output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "\n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(tweet, freqs)\n",
    "    # make the prediction using x and theta\n",
    "    y_pred = sigmoid(np.dot(x, theta))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee980d",
   "metadata": {},
   "source": [
    "#### Determine the model precision \n",
    "* Use your 'predict_tweet' function to make predictions on each tweet in the test set.\n",
    "* If the prediction is > 0.5, set the model's classification 'y_hat' to 1, otherwise set the model's classification 'y_hat' to 0. 0.5 plays a role of the decision threshold here.\n",
    "* A prediction is accurate when the y_hat equals the test_y.  Sum up all the instances when they are equal and divide by $n$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f17ce587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regression(test_x, test_y, freqs, theta, predict_tweet=predict_tweet):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        test_x: a list of tweets\n",
    "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        theta: weight vector of dimension (3, 1)\n",
    "    Output: \n",
    "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
    "    \"\"\"   \n",
    "    # the list for storing predictions\n",
    "    y_hat = list()\n",
    "    \n",
    "    for tweet in test_x:\n",
    "        # get the label prediction for the tweet\n",
    "        y_pred = predict_tweet(tweet, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            # append 1.0 to the list\n",
    "            y_hat.append(1.0)\n",
    "        else:\n",
    "            # append 0 to the list\n",
    "            y_hat.append(0.0)\n",
    "\n",
    "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
    "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
    "    accuracy = np.sum(y_hat == np.squeeze(test_y)) / len(test_y)    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "373d55aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.9960\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, w)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94ea3e",
   "metadata": {},
   "source": [
    "#### Before using LogisticRegression from scikit learn we prapare data in 4 steps:\n",
    "\n",
    "#### 1. **Create feature matrix for training set**:\n",
    "- `train_x_vec = np.zeros((len(train_x), 3))`: Create empty matrix of size (8000, 3)\n",
    "- Each row = 1 tweet, each column = 1 feature\n",
    "- 3 columns: [bias_term, positive_count, negative_count]\n",
    "\n",
    "#### 2. **Fill data into the matrix**:\n",
    "- Loop through each tweet in `train_x` (8000 tweets)\n",
    "- `extract_features(train_x[i], freqs)`: Extract 3 features from tweet i\n",
    "- `train_x_vec[i, :] = ...`: Store feature vector in row i\n",
    "\n",
    "#### 3. **Do the same for test set**:\n",
    "- `test_x_vec`: Matrix (2000, 3) for test data\n",
    "- Same processing approach as training set\n",
    "\n",
    "#### 4. **Results obtained**:\n",
    "- **Old input**: List of tweets as text\n",
    "- **New output**: Numerical matrix compatible with sklearn\n",
    "- Example: Tweet \"I love this!\" ‚Üí [1, 15, 2] (bias=1, pos_words=15, neg_words=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c59e38bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_vec = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    train_x_vec[i, :] = extract_features(train_x[i], freqs)\n",
    "\n",
    "test_x_vec = np.zeros((len(test_x), 3))\n",
    "for i in range(len(test_x)):\n",
    "    test_x_vec[i, :] = extract_features(test_x[i], freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87013c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_x_vec, train_y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a3969",
   "metadata": {},
   "source": [
    "#### Predictions are made using the predict() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c721974d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_x_vec)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbe5db56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Performance ===\n",
      "Accuracy:  0.9950\n",
      "Precision: 0.9920\n",
      "Recall:    0.9980\n",
      "F1-Score:  0.9950\n",
      "\n",
      "Correct predictions: 1990/2000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = model.predict(test_x_vec)\n",
    "y_true = test_y.ravel()\n",
    "\n",
    "print(\"=== Model Performance ===\")\n",
    "print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
    "print(f\"F1-Score:  {f1_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "# S·ªë l∆∞·ª£ng d·ª± ƒëo√°n ƒë√∫ng/sai\n",
    "correct = np.sum(y_pred == y_true)\n",
    "total = len(y_true)\n",
    "print(f\"\\nCorrect predictions: {correct}/{total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e963a25",
   "metadata": {},
   "source": [
    "### The comparision between using Logistic Regression model from scikit learn and the custom-built model that we plemented from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034dc09",
   "metadata": {},
   "source": [
    "Overall, both models perform quite similarly, but the **custom-built model** is slightly better (accuracy score of **0.996**).\n",
    "\n",
    "**Custom-built model**\n",
    "**Strengths:**\n",
    "\n",
    "* Full control over the algorithm and hyperparameters\n",
    "* Clear understanding of every step in the training process (cost function, gradient)\n",
    "\n",
    "**Weaknesses:**\n",
    "\n",
    "* Slower ‚Äì requires 10,000 iterations with a small learning rate\n",
    "* No regularization ‚Äì higher risk of overfitting\n",
    "\n",
    "**Scikit-learn model**\n",
    "**Strengths:**\n",
    "\n",
    "* Fast and optimized ‚Äì includes convergence detection\n",
    "* Built-in regularization ‚Äì reduces the risk of overfitting\n",
    "* Provides multiple metrics ‚Äì precision, recall, F1-score\n",
    "\n",
    "**Weaknesses:**\n",
    "\n",
    "* Functions more like a black box ‚Äì less control over the training process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11d923",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "Analyze certain examples that our logistic regression algorithm predicted wrongly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cebe5125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicted Tweet\n",
      "THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
      "THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
      "1\t0\t0.27510209\tsure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "1\t0\t0.29717304\tuff itna miss karhi thi ap :p\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
      "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
      "0\t1\t0.71039287\tu prob fun david\n",
      "--------------------------------------------------\n",
      "THE TWEET IS: @bumkeyyfel b-butt : ( isn't black cat a bad luck ene\n",
      "THE PROCESSED TWEET IS: ['b-butt', 'black', 'cat', 'bad', 'luck', 'ene']\n",
      "0\t1\t0.52277660\tb-butt black cat bad luck ene\n",
      "--------------------------------------------------\n",
      "THE TWEET IS: pats jay : (\n",
      "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
      "0\t1\t0.62316894\tpat jay\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n",
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n",
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TWEET IS: @bae_ts WHATEVER STIL L YOUNG &gt;:-(\n",
      "THE PROCESSED TWEET IS: ['whatev', 'stil', 'l', 'young', '>:-(']\n",
      "0\t1\t0.61469227\twhatev stil l young >:-(\n",
      "--------------------------------------------------\n",
      "THE TWEET IS: don't sleep. I'm here : (\n",
      "THE PROCESSED TWEET IS: ['sleep']\n",
      "0\t1\t0.52039270\tsleep\n",
      "--------------------------------------------------\n",
      "THE TWEET IS: the internet is being a total bitch : (\n",
      "THE PROCESSED TWEET IS: ['internet', 'total', 'bitch']\n",
      "0\t1\t0.58352454\tinternet total bitch\n",
      "--------------------------------------------------\n",
      "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
      "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
      "0\t1\t0.61732040\tbelov grandmoth\n",
      "--------------------------------------------------\n",
      "THE TWEET IS: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n",
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n",
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n",
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PROCESSED TWEET IS: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']\n",
      "0\t1\t0.70152924\tsr financi analyst expedia inc bellevu wa financ expediajob job job hire\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\3443539414.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n"
     ]
    }
   ],
   "source": [
    "# Error analysis for sklearn model\n",
    "print('Label Predicted Tweet')\n",
    "for i, (x, y) in enumerate(zip(test_x, test_y)):\n",
    "    # Extract features for single tweet\n",
    "    x_features = extract_features(x, freqs).reshape(1, -1)  # Reshape for sklearn\n",
    "    \n",
    "    # Get prediction probability and class\n",
    "    y_hat_prob = model.predict_proba(x_features)[0, 1]  # Probability of class 1\n",
    "    y_hat_class = model.predict(x_features)[0]  # Predicted class\n",
    "    \n",
    "    # Check if prediction is wrong\n",
    "    if np.abs(y - y_hat_class) > 0:\n",
    "        print('THE TWEET IS:', x)\n",
    "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
    "        print('%d\\t%d\\t%0.8f\\t%s' % (int(y), int(y_hat_class), y_hat_prob, ' '.join(process_tweet(x))))\n",
    "        print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aac92f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicted Tweet\n",
      "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
      "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
      "1\t0.47137167\tb'uff itna miss karhi thi ap :p'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\this pc\\AppData\\Local\\Temp\\ipykernel_15508\\1879124182.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
      "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
      "0\t0.53251630\tb'u prob fun david'\n",
      "THE TWEET IS: pats jay : (\n",
      "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
      "0\t0.50095500\tb'pat jay'\n",
      "THE TWEET IS: @bae_ts WHATEVER STIL L YOUNG &gt;:-(\n",
      "THE PROCESSED TWEET IS: ['whatev', 'stil', 'l', 'young', '>:-(']\n",
      "0\t0.50032454\tb'whatev stil l young >:-('\n",
      "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
      "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
      "0\t0.50000008\tb'belov grandmoth'\n",
      "THE TWEET IS: @CHEDA_KHAN Thats life. I get calls from people I havent seen in 20 years and its always favours : (\n",
      "THE PROCESSED TWEET IS: ['that', 'life', 'get', 'call', 'peopl', 'havent', 'seen', '20', 'year', 'alway', 'favour']\n",
      "0\t0.50564988\tb'that life get call peopl havent seen 20 year alway favour'\n",
      "THE TWEET IS: Sr. Financial Analyst - Expedia, Inc.: (#Bellevue, WA) http://t.co/ktknMhvwCI #Finance #ExpediaJobs #Job #Jobs #Hiring\n",
      "THE PROCESSED TWEET IS: ['sr', 'financi', 'analyst', 'expedia', 'inc', 'bellevu', 'wa', 'financ', 'expediajob', 'job', 'job', 'hire']\n",
      "0\t0.51644293\tb'sr financi analyst expedia inc bellevu wa financ expediajob job job hire'\n",
      "THE TWEET IS: @ITVCentral #Midlands Yes thanks for the depressing weather forecast, where the word 'rain' was mentioned several times :-(\n",
      "THE PROCESSED TWEET IS: ['midland', 'ye', 'thank', 'depress', 'weather', 'forecast', 'word', 'rain', 'mention', 'sever', 'time', ':-(']\n",
      "0\t0.53527788\tb'midland ye thank depress weather forecast word rain mention sever time :-('\n"
     ]
    }
   ],
   "source": [
    "# Error analysis for custom-built model\n",
    "print('Label Predicted Tweet')\n",
    "for x,y in zip(test_x,test_y):\n",
    "    y_hat = predict_tweet(x, freqs, w)\n",
    "\n",
    "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
    "        print('THE TWEET IS:', x)\n",
    "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
    "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0256ee12",
   "metadata": {},
   "source": [
    "#### Error analysis:\n",
    "**Consistency in Preprocessing:** Both the scikit-learn and custom-built logistic regression models apply the same tweet preprocessing steps.\n",
    "\n",
    "**Implementation Variations:** Differences in how logistic regression is executed in each model lead to slight prediction discrepancies.\n",
    "\n",
    "**Prediction Outcomes:** These implementation nuances cause small shifts in the probability scores, particularly near the 0.5 decision threshold, which can result in a few tweets being labeled differently.\n",
    "\n",
    "**Practical Implications:** Although their overall results are closely aligned, these boundary-level differences may influence the final sentiment classification of certain tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fdbf8b",
   "metadata": {},
   "source": [
    "#### Inconclude:\n",
    "\n",
    "Using Logistic Regression model from scikit learn can be evaluated as follows:\n",
    "\n",
    "**Strengths:**\n",
    "\n",
    "* **User-Friendly:** Simple to implement with concise code thanks to well-optimized libraries.\n",
    "* **Speed:** Runs efficiently and generally faster because of scikit-learn‚Äôs high level of optimization.\n",
    "* **Rich Evaluation:** Conveniently produces a full set of classification metrics and reports.\n",
    "\n",
    "**Limitations:**\n",
    "\n",
    "* **Limited Transparency:** The internal workings of the algorithm are more abstract, offering less visibility into the detailed mechanics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
